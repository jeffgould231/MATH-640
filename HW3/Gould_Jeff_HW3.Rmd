---
title: "Assignment 3"
author: "Jeff Gould"
date: "3/4/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Theoretical Exercises

## 1)

\begin{align*}
Y_i \stackrel{iid}{\sim} Gamma(\alpha,  \beta) \\
P(\alpha, \beta) \propto \frac{\beta^{\alpha s}}{\Gamma(\alpha)^r}p^{\alpha -1}e^{-\beta q}
\end{align*}

$$\mathcal{L}(\alpha, \beta | y_i, \dots y_n) = \prod_{i=1}^n \frac{\beta^{\alpha}}{\Gamma(\alpha)}y_i^{\alpha - 1}e^{-\beta y_i} = \frac{\beta^{n\alpha}}{\Gamma(\alpha)^n}\left(\prod_{i=1}^ny_i\right)^{\alpha - 1}e^{-\beta \sum y_i}
$$

\begin{align*}
\mathcal{L}(y | \alpha, \beta)p(\alpha,  \beta)  \propto \left(\frac{\beta^{n\alpha}}{\Gamma(\alpha)^n}\left(\prod_{i=1}^ny_i\right)^{\alpha - 1}e^{-\beta \sum y_i}  \right) \left(\frac{\beta^{\alpha s}}{\Gamma(\alpha)^r}p^{\alpha -1}e^{-\beta q} \right) = \\ \frac{\beta^{\alpha(n+s)}}{\Gamma(\alpha)^{n+r}}\left(p\prod_{i=1}^n y_i\right)^{\alpha -  1}e^{-\beta (\sum y_i + q)}
\end{align*}

Let: $p' = p\prod y_i$, $q' = q + \sum y_i$, $s' = s+n$, and $r' = n+r$


$$\frac{\beta^{\alpha(n+s)}}{\Gamma(\alpha)^{n+r}}\left(p\prod_{i=1}^n y_i\right)^{\alpha -  1}e^{-\beta (\sum y_i + q)} = \frac{\beta^{\alpha s'}}{\Gamma(\alpha)^{r'}}(p')^{\alpha - 1}e^{-\beta q'}$$

This takes the same form as the joint prior, therefore the prior is a conjugate prior for a Gamma distribution with unknown parameters $\alpha$ and $\beta$





## 2)

$y \sim MVN(X\beta, \lambda^{-1}I_{n\times n)}$

$\pi(\beta, \lambda) \propto \lambda^{-1}$

\begin{align*}
\begin{split}
\mathcal{L}(Y | X, \beta, \lambda^{-1}) &\propto |\lambda^{-1} I_{n \times n}|^{-1/2} \exp\left[  -\frac{1}{2} (Y - X\beta)'(\lambda^[-1]I)^{-1}(Y - X\beta) \right] \\
&= \lambda^{n/2} \exp \left[-\frac{\lambda}{2}(Y - X \beta)'(Y - X\beta) \right]
\end{split}
\end{align*}

\begin{align*}
\begin{split}
P(\beta, \lambda)  &\propto  \pi(\beta, \lambda)\mathcal{L}(Y | X, \beta, \lambda^{-1}) \\ 
& \propto (\lambda^{-1})\lambda^{n/2}\exp\left[-\frac{\lambda}{2}(Y - X\beta)'(Y - X\beta) \right] \\
&= (\lambda)^{n/2 -1} \exp\left[-\frac{\lambda}{2}(Y - X\beta)'(Y - X\beta) \right] \\ 
&= (\lambda)^{n/2 -1} \exp \left[-\frac{\lambda}{2}\{(Y - X \hat{\beta})' ( Y - X \hat{\beta}) + (\hat{\beta} - \beta)' X'X (\hat{\beta} -\beta)\} \right] \\
&=(\lambda)^{n/2 -1} \exp \left[-\frac{\lambda}{2}\{(Y - X \hat{\beta})' ( Y - X \hat{\beta}) \}\right] \exp\left[-\frac{\lambda}{2}\{(\hat{\beta} - \beta)' X'X (\hat{\beta} -\beta) \} \right]
\end{split}
\end{align*}


So for the marginal distribution of $\beta$:

$P(\beta|  \lambda, Y, X) \propto \exp\left[-\frac{1}{2\lambda^{-1}}\{(\hat{\beta} - \beta)' X'X (\hat{\beta} -\beta) \} \right]$

Which is the kernel for a multivariate normal distribution with mean = $\hat{\beta}$ and a Covariance matrix of $\Sigma = \lambda^{-1}(X'X)^{-1}$









## 3) 

$P(\theta | W) \sim \mathcal{N}(\hat{\theta}, [I(\hat{\theta})]^{-1})$

$I[\theta] = - \frac{d^2}{d\theta^2} \log[P(\theta|W)]$

\begin{align*}
\begin{split}
P(\theta|W) &\propto \pi(\theta)\mathcal{L}(W|\theta) \\ 
&\propto  (\tau^2)^{-1}\prod_{i=1}^n \frac{1}{\sqrt{2\pi\tau^2}}\exp[-\frac{1}{2}\frac{(w_i - \mu)^2}{\tau^2}] \\ 
&\propto (\tau^2)^{-(n/2 + 1)}\exp\left[-\frac{1}{2\tau^2}\sum(w_i - \mu)^2 \right]
\end{split}
\end{align*}

\begin{align*}
\begin{split}
\log P(\theta|W) &= -(n/2 + 1)\log(\tau^2) - \frac{1}{2 \tau^2}\sum(w_i - \mu)^2 \\
\frac{\partial}{\partial \mu}\log P &= \frac{1}{\tau^2}\sum(w_i - \mu) = 0 \rightarrow \\ 
\sum(w_i - \mu) &= 0 \rightarrow \\  
\hat{\mu} &= \frac{1}{n} \sum w_i = \bar{w} \\
\\
\frac{\partial^2}{\partial \mu^2}\log P &=\frac{\partial}{\partial \mu}\frac{1}{\tau^2}\sum(w_i - \mu) =\frac{-n}{\tau^2} \\
\\
\frac{\partial}{\partial \tau^2}\log P &=\frac{-(n/2 +1)}{\tau^2} + \frac{1}{2(\tau^2)^2\sum(w_i - \mu)^2} = 0 \rightarrow \\ \frac{1}{2(\tau^2)^2}\sum(w_i - \bar{w})^2 &= \frac{(n/2 + 1)}{\tau^2} \rightarrow \frac{1}{2}\sum(w_i - \bar{w})^2 = \tau^2(n/2 + 1) \rightarrow \\ 
\hat{\tau}^2 &= \frac{1}{n+2} \sum(w_i - \bar{w})^2 \\
\\
\frac{\partial^2}{\partial (\tau^2)^2}\log P &=\frac{\partial^2}{\partial (\tau^2)}\left[\frac{-(n/2 +1)}{\tau^2} + \frac{1}{2(\tau^2)^2\sum(w_i - \mu)^2}\right] \\ 
&= \frac{(n/2 +1)}{(\tau^2)^2} - (\tau^2)^{-3}\sum(w_i-\mu)^2 \\
\\
\\
\frac{\partial^2}{\partial \mu \partial (\tau^2)} \log P &= \frac{\partial}{\partial \tau^2}\left[ \frac{1}{\tau^2}\sum(w_i - \mu) \right]  \\
&= -(\tau^2)^{-2}\sum(w_i - \mu)
\end{split}
\end{align*}



\begin{align*}
\begin{split}
I &= - \left[\begin{array}{ll}
\frac{\partial^2}{\partial \mu^2} & \frac{\partial^2}{\partial \mu \partial \tau^2} \\
\frac{\partial^2}{\partial \mu \partial \tau^2} & \frac{\partial^2}{\partial(\tau^2)^2} 
\end{array} \right] \\
&= -\left[\begin{array}{ll} 
\frac{-n}{\tau^2} & -(\tau^2)^{-2}\sum(w_i - \mu) \\
-(\tau^2)^{-2}\sum(w_i - \mu) & \frac{(n/2 +1)}{(\tau^2)^2} - (\tau^2)^{-3}\sum(w_i-\mu)^2
\end{array}\right] \\
&= \left[\begin{array}{ll} 
\frac{n}{\tau^2} & (\tau^2)^{-2}\sum(w_i - \mu) \\
(\tau^2)^{-2}\sum(w_i - \mu) & -\frac{(n/2 +1)}{(\tau^2)^2} + (\tau^2)^{-3}\sum(w_i-\mu)^2
\end{array}\right]
\end{split}
\end{align*}

\\

\

\

\begin{align*}
\begin{split}
I(\theta)|_{\theta = \hat{\theta}} = \left[ 
\begin{array}{ll}
\frac{n}{n+2}\sum(w_i - \bar{w})^2 &  (\frac{\sum(w_i - \bar{w})^2}{n+2})^{-2}\sum(w_i - \bar{w}) \\
(\frac{\sum(w_i - \bar{w})^2}{n+2})^{-2}\sum(w_i - \bar{w}) & -\frac{n/2  +1}{(\frac{1}{n+2}\sum (w_i - \bar{w})^2)^2} + (\frac{\sum (w_i - \bar{w})^2}{n+2})^{-3}\sum(w_i - \bar{w})^2
\end{array}
\right]
\end{split}
\end{align*}


And so, $(\mu, \tau^2) \sim \mathcal{MVN}(\hat{\theta}, I(\hat{\theta})^{-1})$, where $\hat{\theta}$ and $I(\hat{\theta})$ are as defined above



# Analysis Exercises

## 1)

\begin{align*}
f_X(x|\lambda, k) &= \frac{1}{(k-1)!}\lambda^k x^{k-1}e^{-\lambda x}
f_X(x|\lambda, k=22) &= \frac{1}{(22-1)!}\lambda^{22} x^{22-1}e^{-\lambda x}
\end{align*}


$\pi(\lambda) \propto [J(\lambda)]^{1/2} \\ J(\lambda) = -E\left[\frac{d^2 l(x|\theta)}{d \theta^2} | \theta\right]$

$\mathcal{L}(X|\lambda) = \frac{1}{(22-1)!}\lambda^{22} x^{22-1}e^{-\lambda x} \rightarrow \log \mathcal{L} \propto 22 \log(\lambda) + 21 \log(x) - \lambda x \rightarrow \frac{d l}{d \lambda} = \frac{22}{\lambda} - x \rightarrow \frac{d^2l}{d\lambda^2} = -\frac{22}{\lambda^2}$

$-E[-\frac{22}{\lambda^2}|\lambda] = \frac{22}{\lambda^2}$

So Jeffrey's Prior: $\pi(\lambda) = \frac{\sqrt{22}}{\lambda} \propto \frac{1}{\lambda}$


To get the normal approximation:

$\pi\mathcal{L}(x) = \frac{1}{\lambda} \prod_{i=1}^n \frac{1}{(22-1)!}\lambda^{22} x_i^{22-1} e^{-\lambda x_i} \propto \lambda^{22n-1}\prod_{i=1}^nx_i^{22-1} e^{-\lambda x_i} \rightarrow \log \mathcal{L} = (22n-1)\log\lambda + \sum\log(x_i) + \lambda \sum(x_i)$

$\frac{\partial}{\partial \lambda}\log \mathcal{L} = \frac{22n-1}{\lambda} - \sum x_i = 0 \rightarrow \hat{\lambda} = \frac{22n-1}{\sum x_i}$



$\frac{\partial^2}{\partial \lambda^2}\log \mathcal{L} = -\frac{22n-1}{\lambda^2} \rightarrow  I(\hat{\lambda}) = \frac{22n-1}{(\frac{22n-1}{\sum x_i})^2} = \frac{(\sum x_i)^2}{22n-1}$

$\lambda \sim \mathcal{N}\left(\frac{22n-1}{\sum x_i}, \frac{(\sum x_i)^2}{22n-1}\right)$





```{r }
library(tidyverse)
incidence <- read.delim(file = "incidenceUK.txt")
k <- 22
n <- nrow(incidence)
x_i_male <- sum(incidence$male)
x_i_female <- sum(incidence$female)
B <- 10000

Lambda <- data.frame(lambda_male = rep(NA, B),
                      lambda_female = rep(NA,B))

set.seed(2020)
Lambda$lambda_male <- rnorm(n = B, mean = (k*n-1)/x_i_male, sd = sqrt((x_i_male)^2 / (k * n - 1)))
set.seed(2020)
Lambda$lambda_female <- rnorm(n = B, mean = (k*n-1)/x_i_female, sd = sqrt((x_i_female)^2 / (k * n - 1)))

ggplot(data = Lambda) +
  geom_density(aes(x = lambda_male), alpha = 0.5, color = "blue", fill = "blue") +
  geom_density(aes(x = lambda_female), alpha = 0.5, color = "red", fill = "red")  +
  theme_bw()


```




## 2)


```{r }
coup <- read.delim("coup1980.txt", sep = " ")
X <- as.matrix(coup[,3:5])
Y <- coup[,2]
B <- 10000
library(mvtnorm)
library(MCMCpack)

n <- length(Y)
k <- ncol(X)

bhat	<- c(solve(t(X)%*%X)%*%(t(X)%*%Y))
SSY	<- t(Y - X%*%bhat)%*%(Y - X%*%bhat)
XtXi	<- solve(t(X)%*%X)

rbeta	<- matrix(0, nrow = B, ncol = k)

shape <- (n - k)/2
rate <- (1/2) * t(Y - X %*% bhat) %*% (Y - X %*% bhat)

set.seed(1980)
rsig <- rinvgamma(B, shape, rate)

for(i in 1:B){
  CovX		<- rsig[i]*XtXi
  rbeta[i,]	<- c(rmvnorm(1, mean = bhat, sigma = CovX))
}

rbMat	   <- apply(rbeta, 2, quantile, probs = c(0.5, 0.025, 0.975))
postp    <- apply(rbeta > 0, 2, mean)
outMat   <- cbind(t(rbMat), postp)
rownames(outMat) <- colnames(X)

```




